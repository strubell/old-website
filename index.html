<!DOCTYPE html> 
<html> 
<head> 
	<title>Emma Strubell</title>

	<link href="style.css" rel="stylesheet" type="text/css" />
    <link href='//fonts.googleapis.com/css?family=Titillium+Web' rel='stylesheet' type='text/css'>
    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">
</head> 

<body> 
	<div class="maincontainer">
		<div class="header"><h1>Emma Strubell</h1></div>
		<div class="main">
			I am an Assistant Professor in the <a href="https://www.lti.cs.cmu.edu/">Language Technologies Institute</a> in the <a href="https://www.cs.cmu.edu/">School of Computer Science</a> at <a href="https://www.cmu.edu/">Carnegie Mellon University</a>.
			<p>
			<p>I earned my Ph.D. from 
				<a href="http://www.cs.umass.edu">UMass Amherst</a> 
				working in the 
				<a href="http://www.iesl.cs.umass.edu">Information 
					Extraction and Synthesis Laboratory</a> 
				with 
				<a href="http://people.cs.umass.edu/~mccallum/">Andrew
					McCallum</a>. 
				Previously, I earned a B.S. in Computer Science from
				the <a href="http://www.umaine.edu">University of Maine</a> with a minor in math,
				where I applied models from mathematical biology to the spread of internet worms with Professor
                <a href="http://math.umaine.edu/~hiebeler/"> David Hiebeler </a>
                in his <a href="http://www.math.umaine.edu/~hiebeler/speedlab/">
                Spatial Population Ecological and Epidemiological Dynamics</a> Lab. I've also spent time as an intern and visiting researcher at Amazon, IBM, Google and Facebook AI Research.
			</p>

			
			<h1>Research Interests</h1>
            <p><strong>I am interested in developing new machine learning techniques to facilitate fast and robust natural language processing.</strong></p>

            <p>Core natural language processing (NLP) tasks such as part-of-speech tagging, syntactic parsing and entity recognition have come of age thanks to advances in machine learning. For example, the task of <em>semantic role labeling</em> (annotating <em>who</em> did <em>what</em> to <em>whom</em>) has seen nearly 40% error reduction over the past decade. NLP has reached a level of maturity long-awaited by domain experts who wish to leverage natural language analysis to inform better decisions and effect social change. By deploying these systems <strong>at scale on billions of documents across many domains</strong> practitioners can consolidate raw text into structured, actionable data. These cornerstone NLP tasks are also <strong>crucial building blocks to higher-level natural language understanding</strong> (NLU) that our field has yet to accomplish, such as whole-document understanding and human-level dialog.</p>

            <p>In order for NLP to effectively process raw text across many domains, <strong>we require models that are both robust to different styles of text and computationally efficient</strong>. The success described above has been achieved in those limited domains for which we have expensive annotated data; models that obtain state-of-the-art accuracy in these data-rich settings are typically neither trained nor evaluated for accuracy out-of-domain. Users also have practical concerns about model responsiveness, turnaround time in large-scale analysis, electricity costs, and consequently environmental conservation, but the highest accuracy systems also have high computational demand. As hardware advances, NLP researchers tend to increase model complexity in step.</p>

            <p><strong>My research enables a diversity of domain experts to leverage NLU at large scale with the goal of informing decision-making and practical solutions to far-reaching problems.</strong> Towards this end, I provide <strong>fundamental advances in computational efficiency and robustness.</strong> To facilitate computational efficiency I design new training and inference algorithms cognizant of strengths in the latest tensor processing hardware, and eliminate redundant computation through joint modeling across many tasks. I will enable high accuracy across diverse natural language domains by developing joint models where parameter sharing improves generalization, paired with novel methods for adversarial training that will enable transfer to new domains and languages without labeled data. I will apply my research broadly to low-level NLP as well as high-level NLU tasks. In conjunction with these new machine learning techniques, I will collaborate with domain experts to make a positive mark on society.</p>
<!-- 			<p><strong>I am interested in developing new machine learning techniques to facilitate fast (and accurate)
                natural language processing of text.</strong></p>
            <p>
			Techniques for low-level NLP tasks such as part-of-speech tagging, named entity recognition and syntactic dependency parsing are now accurate enough to be of use to practitioners who wish to extract structured information from unstructured text. This can include blog posts and discussion forums on the web, or the text of scientific research papers. Though we now wish to deploy these tools on billions of documents, many of the most accurate models were designed with no regard for computational cost. In response, our work aims to design machine learning algorithms to facilitate fast inference in NLP models while sacrificing as little accuracy as possible. 
			<p><p>
			My research focuses on two avenues for improving the speed-accuracy trade-off: First, we develop models which can quickly build up rich representations of tokens in context used as features in a <em>sequential prediction</em> model, where sequence labeling is performed as a series of independent multi-class classifications. This approach allows for much faster inference than e.g. structured prediction in a graphical model while maintaining accuracy via high-quality feature representations incorporating wide context and a concept of neighboring labels. Second, we unify related NLP tasks into a single end-to-end model which reasons in the joint space of output labels. With this approach we aim to increase accuracy by reducing cascading errors and leveraging shared statistics of co-occurring labels, while at the same time decreasing wall-clock runtime speed by sharing model parameters and computation across tasks. -->

			<h1>Publications</h1>

            <h2>2019</h2>

            <ul class="icons-ul">
                <li><i class="icon-li icon-plus"></i>
                <a href="https://arxiv.org/abs/1906.02243">
                Energy and Policy Considerations for Deep Learning in NLP.</a>
                <strong>Emma Strubell</strong>, Ananya Ganesh and Andrew McCallum.
                <em>Annual Meeting of the Association for Computational Linguistics (<strong>ACL short</strong>). </em>
                Florence, Italy. July 2019.
            </ul>

            <ul class="icons-ul">
                <li><i class="icon-li icon-plus"></i>
                <a href="https://arxiv.org/abs/1905.06939">
                The Materials Science Procedural Text Corpus: Annotating Materials Synthesis Procedures with Shallow Semantic Structures.</a>
                Sheshera Mysore, Zach Jensen, Edward Kim, Kevin Huang, Haw-Shiuan Chang, <strong>Emma Strubell</strong>, Jeffrey Flanigan, Andrew McCallum, Elsa Olivetti.
                <em>LAW XIII 2019: The 13th Linguistic Annotation Workshop (<strong>ACL WS</strong>).</em> Florence, Italy. July 2019.
            </ul>

            <ul class="icons-ul">
                <li><i class="icon-li icon-plus"></i>
                <a href="https://arxiv.org/abs/1901.00032">
                Inorganic Materials Synthesis Planning with Literature-Trained Neural Networks.</a>
                Edward Kim, Zach Jensen, Alexander van Grootel, Kevin Huang, Matthew Staib, Sheshera Mysore, Haw-Shiuan Chang, <strong>Emma Strubell</strong>, Andrew McCallum, Stefanie Jegelka, and Elsa Olivetti.
                <em>arXiv pre-print 1901.00032, in submission.</em>
            </ul>

            <h2>2018</h2>

            <ul class="icons-ul">
                <li><i class="icon-li icon-plus"></i>
                <a href="https://arxiv.org/abs/1804.08199">
                Linguistically-Informed Self-Attention for Semantic Role Labeling.</a>
                <strong>Emma Strubell</strong>, Patrick Verga, Daniel Andor, David Weiss and Andrew McCallum.
                <em>Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP</strong>)</em>. Brussels, Belgium. October 2018. <em><strong>Best long paper award</strong></em>. [<a href="bib/emnlp18-strubell.bib">bibtex</a>] [<a href="https://github.com/strubell/lisa">code</a>] [<a href="doc/lisa-final.key">slides</a>] [<a href="https://vimeo.com/306141078">video</a>]
            </ul>

            <ul class="icons-ul">
                <li><i class="icon-li icon-plus"></i>
                <a href="https://arxiv.org/abs/1811.04773">
                Syntax Helps ELMo Understand Semantics: Is Syntax Still Relevant in a Deep Neural Architecture for SRL?</a>
                <strong>Emma Strubell</strong> and Andrew McCallum.
                <em>Proceedings of the Workshop on the Relevance of Linguistic Structure in Neural Architectures for NLP (<strong>ACL WS</strong>)</em>. Melbourne, Australia. July 2018. [<a href="bib/acl18ws-strubell.bib">bibtex</a>]
            </ul>

            <ul class="icons-ul">
                <li><i class="icon-li icon-plus"></i>
                <a href="https://arxiv.org/abs/1802.10569">
                Simultaneously Self-attending to All Mentions for Full-Abstract Biological Relation Extraction.</a>
                Patrick Verga, <strong>Emma Strubell</strong> and Andrew McCallum.
                <em>Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (<strong>NAACL HLT</strong>)</em>. New Orleans, Louisiana. June 2018. [<a href="bib/naacl18-verga.bib">bibtex</a>] [<a href="https://github.com/patverga/bran">code</a>]
            </ul>

            <ul class="icons-ul">
                <li><i class="icon-li icon-plus"></i>
                <a href="https://aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/17326">
                Multi-Task Learning For Parsing The Alexa Meaning Representation Language.</a>
                Vittorio Perera, Tagyoung Chung, Thomas Kollar and <strong>Emma Strubell</strong>.
                <em>Thirty-Second AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</em>. New Orleans, Louisiana. February 2018. [<a href="bib/aaai18-perera.bib">bibtex</a>]
            </ul>


            <h2>2017</h2>
            <ul class="icons-ul">
                <li><i class="icon-li icon-plus"></i>
                <a href="https://arxiv.org/abs/1711.06872">
                Automatically Extracting Action Graphs From Materials Science Synthesis Procedures.</a>
                Sheshera Mysore, Edward Kim, <strong>Emma Strubell</strong>, Ao Liu, Haw-Shiuan Chang, Srikrishna Kompella, Kevin Huang, Andrew McCallum and Elsa Olivetti.
                <em>NIPS Workshop on Machine Learning for Molecules and Materials (<strong>NIPS WS</strong>)</em>. Long Beach, California. December 2017. <em><strong>Spotlight talk.</strong></em> [<a href="bib/nipsws17-mysore.bib">bibtex</a>] [<a href="doc/nipsws17-poster.pdf">poster</a>] [<a href="doc/nips17ws-action-graphs.pdf">slides</a>]
            </ul>

            <ul class="icons-ul">
                <li><i class="icon-li icon-plus"></i>
                <a href="https://arxiv.org/abs/1710.08312">
                Attending to All Mention Pairs for Full Abstract Biological Relation Extraction.</a>
                Patrick Verga, <strong>Emma Strubell</strong>, Ofer Shai, and Andrew McCallum.
                <em>6th Workshop on Automated Knowledge Base Construction (<strong>AKBC</strong>)</em>. Long Beach, California. December 2017. [<a href="bib/akbc17-verga.bib">bibtex</a>]
            </ul>

            <ul class="icons-ul">
                <li><i class="icon-li icon-plus"></i>
                <a href="http://arxiv.org/abs/1702.02098">
                Fast and Accurate Entity Recognition with Iterated Dilated Convolutions.</a>
                <strong>Emma Strubell</strong>, Patrick Verga, David Belanger, and Andrew McCallum.
                <em>Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP</strong>)</em>. Copenhagen, Denmark. September 2017. [<a href="bib/emnlp17-strubell.bib">bibtex</a>] [<a href="https://www.github.com/iesl/dilated-cnn-ner">code</a>] [<a href="doc/emnlp17-poster.pdf">poster</a>]
            </ul>

            <ul class="icons-ul">
                <li><i class="icon-li icon-plus"></i>
                <a href="https://arxiv.org/abs/1705.00403">
                Dependency Parsing with Dilated Iterated Graph CNNs.</a>
                <strong>Emma Strubell</strong> and Andrew McCallum.
                <em>2nd Workshop on Structured Prediction for Natural Language Processing (<strong>EMNLP WS</strong>)</em>. Copenhagen, Denmark. September 2017. [<a href="bib/emnlp17ws-strubell.bib">bibtex</a>] [<a href="doc/spred-workshop-9-7.key">slides</a>]
            </ul>

            <ul class="icons-ul">
                <li><i class="icon-li icon-plus"></i>
                <a href="https://www.nature.com/articles/sdata2017127">
                Machine-learned and codified synthesis parameters of oxide materials.</a>
                Edward Kim, Kevin Huang, Alex Tomala, Sara Matthews, <strong>Emma Strubell</strong>, Adam Saunders, Andrew McCallum and Elsa Olivetti.
                <em>Nature Scientific Data</em>. 4. 2017.
                [<a href="bib/nsd17-kim.bib">bibtex</a>]</li>
            </ul>

            <ul class="icons-ul">
                <li><i class="icon-li icon-plus"></i>
                <a href="http://dx.doi.org/10.1016/j.jtbi.2017.01.035">
                An epidemiological model of internet worms with hierarchical dispersal and spatial clustering of hosts.</a>
                David E. Hiebeler, Andrew Audibert, <strong>Emma Strubell</strong> and Isaac J. Michaud.
                <em>Journal of Theoretical Biology</em>. 418: 8--15. 2017.
                [<a href="bib/jtb17-hiebeler.bib">bibtex</a>]</li>
            </ul>

            <h2>2016</h2>
            <ul class="icons-ul">
            <li><i class="icon-li icon-plus"></i>
                <a href="https://tac.nist.gov/publications/2016/participant.papers/TAC2016.UMass_IESL.proceedings.pdf">Extracting Multilingual Relations under Limited Resources: TAC 2016 Cold-Start KB construction and Slot-Filling using Compositional Universal Schema</a> Haw-Shiuan Chang, Abdurrahman Munir, Ao Liu, Johnny Tian-Zheng Wei, Aaron Traylor, Ajay Nagesh, Nicholas Monath, Patrick Verga, <strong>Emma Strubell</strong> and Andrew McCallum. <em>Text Analysis Conference (Knowledge Base Population Track) '16 Workshop (<strong>TAC KBP</strong>).</em> Gaithersburg, Maryland, USA. November 2016. [<a href="bib/tackbc16-chang.bib">bibtex</a>]</li>
            </ul>

            <ul class="icons-ul">
            <li><i class="icon-li icon-plus"></i>
                <a href="http://arxiv.org/abs/1511.06396v2">
                Multilingual Relation Extraction using Compositional Universal Schema.</a>
                Patrick Verga, David Belanger, <strong>Emma Strubell</strong>, Benjamin Roth and Andrew McCallum.
                <em>Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (<strong>NAACL HLT</strong>)</em>. San Diego, California. June 2016.
                [<a href="bib/naacl16-verga.bib">bibtex</a>] [<a href="https://github.com/patverga/torch-relation-extraction">code</a>]</li>
            </ul>

            <h2>2015</h2>
            <ul class="icons-ul">
            <li><i class="icon-li icon-plus"></i>
                <a href="https://people.cs.umass.edu/~pat/pdfs/tac_workshop.pdf">
                Building Knowledge Bases with Universal Schema: Cold Start and Slot-Filling Approaches</a> 
                Benjamin Roth, Nicholas Monath, David Belanger, <strong>Emma Strubell</strong>, Patrick Verga and Andrew McCallum. <em>Text Analysis Conference (Knowledge Base Population Track) '15 Workshop (<strong>TAC KBP</strong>).</em> Gaithersburg, Maryland, USA. November 2015. [<a href="bib/tackbc15-roth.bib">bibtex</a>]</li> 
            </ul>

            <ul class="icons-ul">
            <li><i class="icon-li icon-plus"></i>
                <a href="http://www.anthology.aclweb.org/P/P15/P15-1015.pdf">
                Learning Dynamic Feature Selection for Fast Sequential Prediction.</a>
                <strong>Emma Strubell</strong>, Luke Vilnis, Kate Silverstein and Andrew McCallum.
                <em>Annual Meeting of the Association for Computational Linguistics (<strong>ACL</strong>). </em>
                Beijing, China. July 2015. <em><strong>Outstanding paper award</strong></em>.
                [<a href="http://techtalks.tv/talks/learning-dynamic-feature-selection-for-fast-sequential-prediction/61727/">video</a>] [<a href="doc/learning-dynamic-feature-selection.key">slides</a>] [<a href="doc/learning-dynamic-feature-selection-poster.pdf">poster</a>] [<a href="bib/acl15-strubell.bib">bibtex</a>] </li>
            </ul>
            <h2>2014</h2>
			<ul class="icons-ul">
			        <li><i class="icon-li icon-plus"></i>
                        <a href="http://arxiv.org/abs/1410.8498">
                        Training for Fast Sequential Prediction Using Dynamic Feature Selection.</a>
                        <strong>Emma Strubell</strong>, Luke Vilnis, and Andrew McCallum.
                        <em>NIPS Workshop on Modern Machine Learning and NLP (<strong>NIPS WS</strong>). </em>
                        Montreal, Quebec, Canada. December 2014.
                        [<a href="bib/nipsws14-strubell.bib">bibtex</a>]</li>
            </ul>
            <ul class="icons-ul">
                <li><i class="icon-li icon-plus"></i>
                    <a href="http://www.akbc.ws/2014/submissions/akbc2014_submission_26.pdf">
                    Minimally Supervised Event Argument Extraction using Universal Schema.</a>
                    Benjamin Roth, <strong>Emma Strubell</strong>, Katherine Silverstein and Andrew McCallum.
                    <em>4th Workshop on Automated Knowledge Base Construction (<strong>AKBC</strong>). </em>
                    At NIPS '14, Montreal, Quebec, Canada. December 2014.
                    [<a href="bib/akbc14-roth.bib">bibtex</a>]</li>
            </ul>
            <ul class="icons-ul">
                <li><i class="icon-li icon-plus"></i>
                    <a href="">
                    Universal Schema for Slot-Filling, Cold-Start KBP and Event Argument Extraction: UMassIESL at TAC KBP 2014.</a>
                    Benjamin Roth, <strong>Emma Strubell</strong>, John Sullivan, Lakshmi Vikraman, Katherine Silverstein, and Andrew McCallum.
                    <em>Text Analysis Conference (Knowledge Base Population Track) '14 Workshop (<strong>TAC KBP</strong>).</em>
                    Gaithersburg, Maryland, USA. November 2014.
                    [<a href="bib/tackbc14-roth.bib">bibtex</a>]</li>
            </ul>
            <h2>2012</h2>
            <ul class="icons-ul">
                <li><i class="icon-li icon-plus"></i>
                    <a href="http://digitalcommons.library.umaine.edu/cgi/viewcontent.cgi?article=1081&context=honors">
                    Modeling the Spread of Biologically-Inspired Internet Worms.</a>
                    <strong>Emma Strubell</strong>.
                    <em>Undergraduate honors thesis.</em>
                    University of Maine Honors College, Orono, Maine, USA. May 2012.
                    [<a href="bib/thesis12-strubell.bib">bibtex</a>]</li>
            </ul>

			<h1>/etc</h1>
			<p><strong>In my spare time</strong>, I enjoy cooking (with a focus
                on making vegetables delicious), fermenting (kombucha, kimchi, yogurt, sourdough), enjoying the outdoors (backpacking and rock climbing), and training my <a href="img/nala-CT.jpg">dog</a>.
            </p>
            <p> In search of a fast Scala lexer, I forked <a href="http://jflex.de/">JFlex</a> and added the ability to
                emit Scala code. <a href="https://github.com/strubell/jflex-scala">JFlex-scala</a>, and its 
                corresponding maven and sbt plugins, are available on Maven Central. For an example of its
                use, check out the tokenizer in <a href="http://factorie.cs.umass.edu/">FACTORIE</a>.
            </p>
<!--             <p> <a href="http://cs.umass.edu/~pat">Patrick Verga</a> and I made an
                <a href="https://play.google.com/store/apps/details?id=com.pemmaco.networkusage&hl=en">Android app</a>
                for the <a href="https://www.nationstates.net/">NationStates</a> online diplomacy game,
                which now has almost 10,000 downloads. Some day we will clean up the code and open source it!
            </p> -->
            <p> I am also co-author of <a href="https://twitter.com/plant_jones">Plant Jones</a>. He is a semi-intelligent
                plant who tweets negatively about water when he's thirsty, and positively when he's not. His code is available <a href="https://github.com/patverga/plant_jones">here</a>.
            </p>
            <p>In my junior year of college I wrote and presented a tutorial on quantum algorithms aimed for
                undergraduate students in computer science, available <a href="doc/quantum_tutorial.pdf">here</a>, along
                with slides <a href="doc/quantum_presentation_1.pdf">part 1</a> and <a href="doc/quantum_presentation_2.pdf">part 2</a>.
            </p>
            <p><a href="https://www.gentoo.org/main/en/about.xml">Gentoo Linux</a> user since 2005. </p>
		</div><!-- closes main-->
		<div class="contactbox"><div class="contact">
			<img src="img/race_brook.jpg" title="Hiking at Race Brook Falls, MA.">
			<p><span style="padding-left:1px; padding-right:2px;"><i class="fa fa-map-marker fa-lg"></i></span> Pittsburgh, PA, USA</p>
			<p><span style="padding-left:1px; padding-right:2px;"><i class="fa fa-globe"></i></span> strubell.github.io </p>
			<p><span style="padding-right:2px;"><i class="fa fa-envelope"></i></span> strubell [at] cmu [dot] edu</p>
			<p><span style="padding-left:2px; padding-right:2px;"><i class="fa fa-file"></i></span> <a href="doc/emma-strubell-cv.pdf">curriculum vitae (PDF)</a></p>
			<div class="social">
            <span class="so"><a href="http://stackoverflow.com/users/4121413/emma-strubell"><i class="fa fa-stack-overflow fa-2x"></i></a>  &nbsp;&nbsp;</span>
                <span class="gh"><a href="http://github.com/strubell"><i class="fa fa-github-alt fa-2x"></i></a>  &nbsp;&nbsp;</span>
                <span class="twit"><a href="https://twitter.com/strubell"><i class="fa fa-twitter fa-2x"></i></a> &nbsp;&nbsp;</span>
                <span class="qu"><a href="http://www.quora.com/Emma-Strubell"><i class="fa fa-quora fa-2x"></i></a> &nbsp;&nbsp;</span>
                <!-- <span class="fb"><a href="http://www.facebook.com/emmastrubell"><i class="fa fa-facebook-official fa-2x"></i></a> &nbsp;&nbsp;</span> -->
                <!-- <span class="lin"><a href="https://www.linkedin.com/profile/view?id=313657197"><i class="fa fa-linkedin-square fa-2x"></i></a> &nbsp;&nbsp;</span> -->
				<!-- <span class="gp"><a href="http://plus.google.com/u/0/+EmmaStrubell/posts"><i class="fa fa-google-plus-square fa-2x"></i></a> &nbsp;&nbsp;</span> -->
                
			</div>
			<br />
			<br />
		</div></div><!-- closes contact-->
	</div><!-- closes main container-->
	<div style="clear:both;"></div>
	<div class="footer">
		<i class="fa fa-globe"></i> &nbsp; strubell.github.io &nbsp;&nbsp;&nbsp;&nbsp;
		<i class="fa fa-envelope"></i> &nbsp; strubell [at] cmu [dot] edu
		<br />
		Last updated 8 June, 2019.
		<br /><br /><br />
	</div>
</body>
</html>
